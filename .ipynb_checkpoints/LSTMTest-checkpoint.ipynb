{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e537cfd9-e990-409b-98fc-9e5e92432693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2031f41-cb2c-43ee-a74c-9af89a656206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8adb1f7d-5562-4384-a39c-0de47ba6c578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruncatedData\\NYC10\\csv\\CSVScenario-CP1_Session-NYC10_2022-09-14-11-57-16.csv\n",
      "TruncatedData\\NYC11\\csv\\CSVScenario-CP1_Session-NYC11_2022-09-14-16-26-15.csv\n",
      "TruncatedData\\NYC12\\csv\\CSVScenario-CP1_Session-NYC12_2022-09-15-09-44-53.csv\n",
      "TruncatedData\\NYC13\\csv\\CSVScenario-CP1_Session-NYC13_2022-09-15-11-13-58.csv\n",
      "TruncatedData\\NYC14\\csv\\CSVScenario-CP1_Session-NYC14B_2022-09-15-15-29-12.csv\n",
      "TruncatedData\\NYC15\\csv\\CSVScenario-CP1_Session-NYC15_2022-09-16-09-57-43.csv\n",
      "TruncatedData\\NYC16\\csv\\CSVScenario-CP1_Session-NYC16_2022-09-16-15-37-55.csv\n",
      "TruncatedData\\NYC17\\csv\\CSVScenario-CP1_Session-NYC17_2022-09-16-17-28-03.csv\n",
      "TruncatedData\\NYC18\\csv\\CSVScenario-CP1_Session-NYC18_2022-09-19-11-41-57.csv\n",
      "TruncatedData\\NYC19\\csv\\CSVScenario-CP1_Session-NYC19_2022-09-19-13-40-44.csv\n",
      "TruncatedData\\NYC2\\csv\\CSVScenario-CP1_Session-NYC2_2022-08-09-14-52-30.csv\n",
      "TruncatedData\\NYC20\\csv\\CSVScenario-CP1_Session-NYC20_2022-09-19-15-12-43.csv\n",
      "TruncatedData\\NYC21\\csv\\CSVScenario-CP1_Session-NYC21_2022-09-19-17-11-48.csv\n",
      "TruncatedData\\NYC23\\csv\\CSVScenario-CP1_Session-NYC23_2022-09-21-14-29-05.csv\n",
      "TruncatedData\\NYC24\\csv\\CSVScenario-CP1_Session-NYC24_2022-10-06-11-32-02.csv\n",
      "TruncatedData\\NYC25\\csv\\CSVScenario-CP1_Session-NYC25_2022-10-07-10-42-23.csv\n",
      "TruncatedData\\NYC26\\csv\\CSVScenario-CP1_Session-NYC26_2022-10-07-15-58-15.csv\n",
      "TruncatedData\\NYC28\\csv\\CSVScenario-CP1_Session-NYC28_2022-10-28-10-02-58.csv\n",
      "TruncatedData\\NYC29\\csv\\CSVScenario-CP1_Session-NYC29_2022-11-09-11-33-35.csv\n",
      "TruncatedData\\NYC29\\csv\\CSVScenario-CP1_Session-NYC29_2022-11-11-11-09-21.csv\n",
      "TruncatedData\\NYC30b\\csv\\CSVScenario-CP1_Session-NYC30b_2022-11-17-10-33-18.csv\n",
      "TruncatedData\\NYC32\\csv\\CSVScenario-CP1_Session-NYC32_2022-11-17-15-07-07.csv\n",
      "TruncatedData\\NYC34\\csv\\CSVScenario-CP1_Session-NYC34_2022-11-21-10-06-04.csv\n",
      "TruncatedData\\NYC37\\csv\\CSVScenario-CP1_Session-NYC37_2022-11-23-15-24-27.csv\n",
      "TruncatedData\\NYC38\\csv\\CSVScenario-CP1_Session-NYC38_2022-11-23-17-01-10.csv\n",
      "TruncatedData\\NYC4\\csv\\CSVScenario-CP1_Session-NYC4_2022-08-12-14-09-37.csv\n",
      "TruncatedData\\NYC40\\csv\\CSVScenario-CP1_Session-NYC40_2022-11-29-15-51-27.csv\n",
      "TruncatedData\\NYC41\\csv\\CSVScenario-CP1_Session-NYC41_2022-12-02-11-04-52.csv\n",
      "TruncatedData\\NYC7\\csv\\CSVScenario-CP1_Session-NYC7_2022-09-12-10-30-17.csv\n",
      "TruncatedData\\NYC8\\csv\\CSVScenario-CP1_Session-NYC8_2022-09-12-11-50-59.csv\n",
      "Epoch 1/50\n",
      "537/537 [==============================] - 2s 2ms/step - loss: 0.1080 - val_loss: 0.1144\n",
      "Epoch 2/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0856 - val_loss: 0.1141\n",
      "Epoch 3/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0775 - val_loss: 0.1199\n",
      "Epoch 4/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0711 - val_loss: 0.1216\n",
      "Epoch 5/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0659 - val_loss: 0.1245\n",
      "Epoch 6/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0614 - val_loss: 0.1208\n",
      "Epoch 7/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0574 - val_loss: 0.1193\n",
      "Epoch 8/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0540 - val_loss: 0.1239\n",
      "Epoch 9/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0505 - val_loss: 0.1365\n",
      "Epoch 10/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0478 - val_loss: 0.1452\n",
      "Epoch 11/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0454 - val_loss: 0.1586\n",
      "Epoch 12/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0433 - val_loss: 0.1710\n",
      "Epoch 13/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0414 - val_loss: 0.1734\n",
      "Epoch 14/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0395 - val_loss: 0.1716\n",
      "Epoch 15/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0382 - val_loss: 0.1765\n",
      "Epoch 16/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0367 - val_loss: 0.1757\n",
      "Epoch 17/50\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 0.0351 - val_loss: 0.1887\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def prepare_data(file_list):\n",
    "    df = pd.concat((pd.read_csv(f, sep=\";\") for f in file_list))\n",
    "    features = df.drop('ThrottleA', axis=1)\n",
    "    target = df['ThrottleA']\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Reshaping the input for LSTM\n",
    "    scaled_features = np.reshape(scaled_features, (scaled_features.shape[0], 1, scaled_features.shape[1]))\n",
    "    \n",
    "    return scaled_features, target, scaler\n",
    "\n",
    "csv_path = Path(\"./TruncatedData\")\n",
    "\n",
    "my_regex = \".+CP(\\d).+\"\n",
    "location_regex = \".+CP(\\d).+(NYC).+\"\n",
    "wanted_CP_number = 1\n",
    "\n",
    "file_list = []\n",
    "for file_path in csv_path.rglob('*.csv'):\n",
    "    if re.match(my_regex, file_path.name):\n",
    "        if re.match(my_regex, file_path.name).group(1) == str(wanted_CP_number):\n",
    "            if re.match(location_regex, file_path.name):\n",
    "                file_list.append(file_path)\n",
    "                print(file_path)\n",
    "\n",
    "scaled_features, target, scaler = prepare_data(file_list)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(scaled_features.shape[1], scaled_features.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=Adam(), loss='mse')\n",
    "\n",
    "# Early stopping  --- This seems very unstable at the current point... Need to play with it more\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15)\n",
    "\n",
    "history = model.fit(scaled_features, target, epochs=50, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27dd8fa1-54ee-4c2c-8b51-9cefb868b88f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models\\model_2023-07-25_14-24-44\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Models\\\\model_2023-07-25_14-24-44\\\\scaler.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "models_path = Path('./Models')\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "now_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "model_path = models_path / f'model_{now_string}'\n",
    "\n",
    "model.save(model_path)\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = model_path / f'scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92fafaa0-2553-45c2-be2a-ac00d71f61c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ThrottleAPredicted\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m new_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVerificationData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCSVScenario-CP1_Session-isr01_2022-05-31-11-44-09.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m new_features \u001b[38;5;241m=\u001b[39m new_data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThrottleA\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m scaled_new_features \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m scaled_new_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(scaled_new_features, (scaled_new_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, scaled_new_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     17\u001b[0m new_target \u001b[38;5;241m=\u001b[39m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThrottleA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\XCData\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\XCData\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:992\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    989\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    991\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m--> 992\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\XCData\\lib\\site-packages\\sklearn\\base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    490\u001b[0m ):\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \n\u001b[0;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\XCData\\lib\\site-packages\\sklearn\\base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    479\u001b[0m     )\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ThrottleAPredicted\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "model_path = Path('./Models/model_2023-07-25_14-24-44')\n",
    "loaded_model = load_model(model_path)\n",
    "scaler_path = model_path / 'scaler.pkl'\n",
    "\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "\n",
    "\n",
    "# Load new data\n",
    "new_data = pd.read_csv(r\".\\VerificationData\\CSVScenario-CP1_Session-ISR02_2022-05-31-15-21-40.csv\", sep=\";\")\n",
    "\n",
    "new_features = new_data.drop('ThrottleA', axis=1)\n",
    "scaled_new_features = loaded_scaler.transform(new_features)\n",
    "scaled_new_features = np.reshape(scaled_new_features, (scaled_new_features.shape[0], 1, scaled_new_features.shape[1]))\n",
    "\n",
    "new_target = new_data['ThrottleA']\n",
    "\n",
    "# Predict\n",
    "predictions = loaded_model.predict(scaled_new_features)\n",
    "\n",
    "# Plotting the actual vs predicted values\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(new_data['ScenarioTime'], new_target.values, label='Actual')\n",
    "plt.plot(new_data['ScenarioTime'], predictions, label='Predicted')\n",
    "plt.title('ThrottleA: Actual vs Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('ThrottleA')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Predict\n",
    "predictions = loaded_model.predict(scaled_new_features)\n",
    "\n",
    "#for prediction in predictions:\n",
    "    #print(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82bda7b-0602-42ab-9703-74ac45c2352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\".\\VerificationData\\CSVScenario-CP1_Session-ISR02_2022-05-31-15-21-40.csv\", sep=\";\")\n",
    "\n",
    "new_features = new_data.drop('ThrottleA', axis=1)\n",
    "new_target = new_data['ThrottleA']\n",
    "\n",
    "model = load_model(\"your_model_path.h5\")  # Replace with your model path\n",
    "scaler = StandardScaler()  # Replace with your scaler\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i in range(len(new_features)):\n",
    "    temp_data = new_features.iloc[0:i+1, :]\n",
    "    \n",
    "    scaled_temp_data = scaler.transform(temp_data)\n",
    "    \n",
    "    scaled_temp_data = np.reshape(scaled_temp_data, (1, scaled_temp_data.shape[0], scaled_temp_data.shape[1]))\n",
    "    \n",
    "    prediction = model.predict(scaled_temp_data)\n",
    "    \n",
    "    predictions.append(prediction[0,0])\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(new_data['ScenarioTime'], new_target.values, label='Actual')\n",
    "plt.plot(new_data['ScenarioTime'], predictions, label='Predicted')\n",
    "plt.title('ThrottleA: Actual vs Predicted')\n",
    "plt.xlabel('Observations')\n",
    "plt.ylabel('ThrottleA')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
